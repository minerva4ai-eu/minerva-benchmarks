LAUNCH_FOLDER: {/leonardo_scratch/large/userinternal/rscheda0/benchmarks/inference/inference-Leonardo/results/deepspeed/sharegpt/gemma-3-12b-it/Nodes_1-GPUs_4-TP_4-PP_1/launch-1}
BENCHMARK_FILE: {/leonardo_scratch/large/userinternal/rscheda0/benchmarks/inference/inference-Leonardo/benchmarks/benchmark_serving.py}
DATASET: {sharegpt}
DATASET_PATH: {/leonardo_scratch/large/userinternal/rscheda0/benchmarks/inference/inference-Leonardo/benchmarks/datasets/ShareGPT_V3_unfiltered_cleaned_split.json}
MODEL: {gemma-3-12b-it}
MODEL_PATH: {/leonardo_scratch/large/userinternal/rscheda0/models/gemma-3-12b-it}
/leonardo_scratch/large/userinternal/rscheda0/benchmarks/inference/inference-Leonardo/env_ds/bin/python
Using TENSOR_PARALLEL: 4
Running concurrency level 50 for MODEL: gemma-3-12b-it
Running concurrency level 100 for MODEL: gemma-3-12b-it
Running concurrency level 200 for MODEL: gemma-3-12b-it
Running concurrency level 300 for MODEL: gemma-3-12b-it
Running concurrency level 400 for MODEL: gemma-3-12b-it
Running concurrency level 500 for MODEL: gemma-3-12b-it
Running concurrency level 1000 for MODEL: gemma-3-12b-it
