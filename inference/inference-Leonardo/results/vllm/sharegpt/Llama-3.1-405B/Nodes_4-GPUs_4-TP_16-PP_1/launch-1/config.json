{
    "env_vars": {
        "MODEL_PATH": "/leonardo_scratch/large/userinternal/lcavall1/llama405_mlperf/model//Llama-3.1-405B",
        "ENVIRONMENT_VLLM": "/leonardo_scratch/large/userinternal/rscheda0/benchmarks/inference/inference-Leonardo/env_vllm",
        "PORT": "2950",
        "LAUNCH_FOLDER": "/leonardo_scratch/large/userinternal/rscheda0/benchmarks/inference/inference-Leonardo/results/vllm/sharegpt/Llama-3.1-405B/Nodes_4-GPUs_4-TP_16-PP_1/launch-1",
        "BENCHMARK_FILE": "/leonardo_scratch/large/userinternal/rscheda0/benchmarks/inference/inference-Leonardo/benchmarks/benchmark_serving.py",
        "DATASET": "sharegpt",
        "DATASET_PATH": "/leonardo_scratch/large/userinternal/rscheda0/benchmarks/inference/inference-Leonardo/benchmarks/datasets/ShareGPT_V3_unfiltered_cleaned_split.json",
        "TP": "16",
        "ADDITIONAL_ARGS": "--max-model-len=32000 --cpu-offload-gb=0.5",
        "MODULES": ""
    }
}
