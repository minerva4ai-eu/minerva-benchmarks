/leonardo_scratch/large/userinternal/rscheda0/benchmarks/inference/inference-Leonardo/env_vllm/bin/python
LAUNCH_FOLDER: {/leonardo_scratch/large/userinternal/rscheda0/benchmarks/inference/inference-Leonardo/results/vllm/sharegpt/Llama-3.1-405B/Nodes_8-GPUs_4-TP_32-PP_1/launch-1}
BENCHMARK_FILE: {/leonardo_scratch/large/userinternal/rscheda0/benchmarks/inference/inference-Leonardo/benchmarks/benchmark_serving.py}
DATASET: {sharegpt}
DATASET_PATH: {/leonardo_scratch/large/userinternal/rscheda0/benchmarks/inference/inference-Leonardo/benchmarks/datasets/ShareGPT_V3_unfiltered_cleaned_split.json}
Node: lrdn2664 - IP: 10.8.0.144
Node: lrdn2674 - IP: 10.8.0.154
Node: lrdn2689 - IP: 10.8.0.169
Node: lrdn2693 - IP: 10.8.0.173
Node: lrdn2707 - IP: 10.8.0.187
Node: lrdn2734 - IP: 10.8.0.214
Node: lrdn2755 - IP: 10.8.0.235
Node: lrdn2759 - IP: 10.8.0.239
Starting HEAD at lrdn2664
/leonardo_scratch/large/userinternal/rscheda0/benchmarks/inference/inference-Leonardo/env_vllm/bin/python
Configuration written to config.json
2025-09-16 14:12:39,597	INFO usage_lib.py:472 -- Usage stats collection is enabled. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.
2025-09-16 14:12:39,597	INFO scripts.py:865 -- [37mLocal node IP[39m: [1m10.8.0.144[22m
2025-09-16 14:12:45,606	SUCC scripts.py:902 -- [32m--------------------[39m
2025-09-16 14:12:45,607	SUCC scripts.py:903 -- [32mRay runtime started.[39m
2025-09-16 14:12:45,607	SUCC scripts.py:904 -- [32m--------------------[39m
2025-09-16 14:12:45,607	INFO scripts.py:906 -- [36mNext steps[39m
2025-09-16 14:12:45,607	INFO scripts.py:909 -- To add another node to this Ray cluster, run
2025-09-16 14:12:45,607	INFO scripts.py:912 -- [1m  ray start --address='10.8.0.144:6379'[22m
2025-09-16 14:12:45,607	INFO scripts.py:921 -- To connect to this Ray cluster:
2025-09-16 14:12:45,607	INFO scripts.py:923 -- [35mimport[39m[26m ray
2025-09-16 14:12:45,607	INFO scripts.py:924 -- ray[35m.[39m[26minit(_node_ip_address[35m=[39m[26m[33m'10.8.0.144'[39m[26m)
2025-09-16 14:12:45,607	INFO scripts.py:936 -- To submit a Ray job using the Ray Jobs CLI:
2025-09-16 14:12:45,607	INFO scripts.py:937 -- [1m  RAY_ADDRESS='http://127.0.0.1:8265' ray job submit --working-dir . -- python my_script.py[22m
2025-09-16 14:12:45,607	INFO scripts.py:946 -- See https://docs.ray.io/en/latest/cluster/running-applications/job-submission/index.html 
2025-09-16 14:12:45,607	INFO scripts.py:950 -- for more information on submitting Ray jobs to the Ray cluster.
2025-09-16 14:12:45,607	INFO scripts.py:955 -- To terminate the Ray runtime, run
2025-09-16 14:12:45,607	INFO scripts.py:956 -- [1m  ray stop[22m
2025-09-16 14:12:45,607	INFO scripts.py:959 -- To view the status of the cluster, use
2025-09-16 14:12:45,607	INFO scripts.py:960 --   [1mray status[22m[26m
2025-09-16 14:12:45,607	INFO scripts.py:964 -- To monitor and debug Ray, view the dashboard at 
2025-09-16 14:12:45,607	INFO scripts.py:965 --   [1m127.0.0.1:8265[22m[26m
2025-09-16 14:12:45,607	INFO scripts.py:972 -- [4mIf connection to the dashboard fails, check your firewall settings and network configuration.[24m
Starting workers Nodes
Starting WORKER 1 at lrdn2674
/leonardo_scratch/large/userinternal/rscheda0/benchmarks/inference/inference-Leonardo/env_vllm/bin/python
Configuration written to config.json
Starting WORKER 2 at lrdn2689
/leonardo_scratch/large/userinternal/rscheda0/benchmarks/inference/inference-Leonardo/env_vllm/bin/python
Configuration written to config.json
Starting WORKER 3 at lrdn2693
/leonardo_scratch/large/userinternal/rscheda0/benchmarks/inference/inference-Leonardo/env_vllm/bin/python
Configuration written to config.json
Starting WORKER 4 at lrdn2707
/leonardo_scratch/large/userinternal/rscheda0/benchmarks/inference/inference-Leonardo/env_vllm/bin/python
Configuration written to config.json
Starting WORKER 5 at lrdn2734
/leonardo_scratch/large/userinternal/rscheda0/benchmarks/inference/inference-Leonardo/env_vllm/bin/python
Configuration written to config.json
Starting WORKER 6 at lrdn2755
/leonardo_scratch/large/userinternal/rscheda0/benchmarks/inference/inference-Leonardo/env_vllm/bin/python
Configuration written to config.json
Starting WORKER 7 at lrdn2759
/leonardo_scratch/large/userinternal/rscheda0/benchmarks/inference/inference-Leonardo/env_vllm/bin/python
Configuration written to config.json
Ray Cluster started correctly
2025-09-16 14:14:08,523	INFO scripts.py:1047 -- [37mLocal node IP[39m: [1m10.8.0.154[22m
2025-09-16 14:14:08,028	INFO scripts.py:1047 -- [37mLocal node IP[39m: [1m10.8.0.169[22m
2025-09-16 14:14:10,663	SUCC scripts.py:1063 -- [32m--------------------[39m
2025-09-16 14:14:08,028	INFO scripts.py:1047 -- [37mLocal node IP[39m: [1m10.8.0.187[22m
2025-09-16 14:14:10,663	SUCC scripts.py:1063 -- [32m--------------------[39m
2025-09-16 14:14:10,664	SUCC scripts.py:1064 -- [32mRay runtime started.[39m
2025-09-16 14:14:10,663	SUCC scripts.py:1063 -- [32m--------------------[39m
2025-09-16 14:14:10,663	SUCC scripts.py:1064 -- [32mRay runtime started.[39m
2025-09-16 14:14:10,664	SUCC scripts.py:1065 -- [32m--------------------[39m
2025-09-16 14:14:10,663	SUCC scripts.py:1064 -- [32mRay runtime started.[39m
2025-09-16 14:14:10,664	SUCC scripts.py:1065 -- [32m--------------------[39m
2025-09-16 14:14:10,664	INFO scripts.py:1067 -- To terminate the Ray runtime, run
2025-09-16 14:14:10,663	SUCC scripts.py:1065 -- [32m--------------------[39m
2025-09-16 14:14:10,664	INFO scripts.py:1067 -- To terminate the Ray runtime, run
2025-09-16 14:14:10,664	INFO scripts.py:1068 -- [1m  ray stop[22m
2025-09-16 14:14:10,663	INFO scripts.py:1067 -- To terminate the Ray runtime, run
2025-09-16 14:14:10,664	INFO scripts.py:1068 -- [1m  ray stop[22m
2025-09-16 14:14:10,663	INFO scripts.py:1068 -- [1m  ray stop[22m
2025-09-16 14:14:10,664	INFO scripts.py:1076 -- [36m[1m--block[22m[39m
2025-09-16 14:14:10,664	INFO scripts.py:1077 -- This command will now block forever until terminated by a signal.
2025-09-16 14:14:10,664	INFO scripts.py:1080 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.
2025-09-16 14:14:10,664	INFO scripts.py:1076 -- [36m[1m--block[22m[39m
2025-09-16 14:14:10,664	INFO scripts.py:1077 -- This command will now block forever until terminated by a signal.
2025-09-16 14:14:08,028	INFO scripts.py:1047 -- [37mLocal node IP[39m: [1m10.8.0.173[22m
2025-09-16 14:14:10,664	SUCC scripts.py:1063 -- [32m--------------------[39m
2025-09-16 14:14:10,664	INFO scripts.py:1076 -- [36m[1m--block[22m[39m
2025-09-16 14:14:10,664	INFO scripts.py:1080 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.
2025-09-16 14:14:10,664	SUCC scripts.py:1064 -- [32mRay runtime started.[39m
2025-09-16 14:14:10,664	INFO scripts.py:1077 -- This command will now block forever until terminated by a signal.
2025-09-16 14:14:10,664	SUCC scripts.py:1065 -- [32m--------------------[39m
2025-09-16 14:14:10,664	INFO scripts.py:1080 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.
2025-09-16 14:14:10,664	INFO scripts.py:1067 -- To terminate the Ray runtime, run
2025-09-16 14:14:10,664	INFO scripts.py:1068 -- [1m  ray stop[22m
2025-09-16 14:14:08,028	INFO scripts.py:1047 -- [37mLocal node IP[39m: [1m10.8.0.214[22m
2025-09-16 14:14:10,663	SUCC scripts.py:1063 -- [32m--------------------[39m
2025-09-16 14:14:10,663	SUCC scripts.py:1064 -- [32mRay runtime started.[39m
2025-09-16 14:14:10,663	SUCC scripts.py:1065 -- [32m--------------------[39m
2025-09-16 14:14:10,664	INFO scripts.py:1067 -- To terminate the Ray runtime, run
2025-09-16 14:14:10,664	INFO scripts.py:1068 -- [1m  ray stop[22m
2025-09-16 14:14:10,664	INFO scripts.py:1076 -- [36m[1m--block[22m[39m
2025-09-16 14:14:10,664	INFO scripts.py:1076 -- [36m[1m--block[22m[39m
2025-09-16 14:14:10,664	INFO scripts.py:1077 -- This command will now block forever until terminated by a signal.
2025-09-16 14:14:10,664	INFO scripts.py:1077 -- This command will now block forever until terminated by a signal.
2025-09-16 14:14:10,664	INFO scripts.py:1080 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.
2025-09-16 14:14:10,664	INFO scripts.py:1080 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.
2025-09-16 14:14:08,028	INFO scripts.py:1047 -- [37mLocal node IP[39m: [1m10.8.0.239[22m
2025-09-16 14:14:10,664	SUCC scripts.py:1063 -- [32m--------------------[39m
2025-09-16 14:14:10,664	SUCC scripts.py:1064 -- [32mRay runtime started.[39m
2025-09-16 14:14:10,664	SUCC scripts.py:1065 -- [32m--------------------[39m
2025-09-16 14:14:10,664	INFO scripts.py:1067 -- To terminate the Ray runtime, run
2025-09-16 14:14:10,664	INFO scripts.py:1068 -- [1m  ray stop[22m
2025-09-16 14:14:10,664	INFO scripts.py:1076 -- [36m[1m--block[22m[39m
2025-09-16 14:14:10,664	INFO scripts.py:1077 -- This command will now block forever until terminated by a signal.
2025-09-16 14:14:10,665	INFO scripts.py:1080 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.
Ray Status
======== Autoscaler status: 2025-09-16 14:14:15.988297 ========
Node status
---------------------------------------------------------------
Active:
 1 node_8d355561459293a72ede9d2b53139a976ce267e1facae9d4a0d899a4
 1 node_cc65e316661fe07b197497fe8f59c8e42ea83ae813f291088401dba8
 1 node_fb1bb00c9134e2bf4aef5ec74351cc93bb382149991224b16b0bb43d
 1 node_85192534de0512bbefc7919b7d29d6fa56897b87853056f9a8d30ddf
 1 node_15ecba731ca2d3b24198f3f61bf7a882998b00f6637636b0405d8a5e
 1 node_365b5b86090731b521380c962842c312e285fd57da44615c98026c5b
 1 node_d50120a9bb735fe7109aeeb41470d3dfaa6e87e5dd939c97e06a4006
Pending:
 (no pending nodes)
Recent failures:
 (no failures)

Resources
---------------------------------------------------------------
Usage:
 0.0/224.0 CPU
 0.0/28.0 GPU
 0B/2.37TiB memory
 0B/1.02TiB object_store_memory

Demands:
 (no resource demands)
VLLM serve loading... Head Node Address: 10.8.0.144
2025-09-16 14:14:32,473	INFO scripts.py:1047 -- [37mLocal node IP[39m: [1m10.8.0.235[22m
2025-09-16 14:14:32,840	SUCC scripts.py:1063 -- [32m--------------------[39m
2025-09-16 14:14:32,840	SUCC scripts.py:1064 -- [32mRay runtime started.[39m
2025-09-16 14:14:32,840	SUCC scripts.py:1065 -- [32m--------------------[39m
2025-09-16 14:14:32,840	INFO scripts.py:1067 -- To terminate the Ray runtime, run
2025-09-16 14:14:32,840	INFO scripts.py:1068 -- [1m  ray stop[22m
2025-09-16 14:14:32,841	INFO scripts.py:1076 -- [36m[1m--block[22m[39m
2025-09-16 14:14:32,841	INFO scripts.py:1077 -- This command will now block forever until terminated by a signal.
2025-09-16 14:14:32,841	INFO scripts.py:1080 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.
2025-09-16 14:14:22,761	INFO cli.py:39 -- [37mJob submission server address[39m: [1mhttp://127.0.0.1:8265[22m
2025-09-16 14:14:24,945	SUCC cli.py:63 -- [32m-------------------------------------------------------[39m
2025-09-16 14:14:24,945	SUCC cli.py:64 -- [32mJob 'raysubmit_GcFT3P9Kk75xEucD' submitted successfully[39m
2025-09-16 14:14:24,945	SUCC cli.py:65 -- [32m-------------------------------------------------------[39m
2025-09-16 14:14:24,946	INFO cli.py:289 -- [36mNext steps[39m
2025-09-16 14:14:24,946	INFO cli.py:290 -- Query the logs of the job:
2025-09-16 14:14:24,946	INFO cli.py:292 -- [1mray job logs raysubmit_GcFT3P9Kk75xEucD[22m
2025-09-16 14:14:24,946	INFO cli.py:294 -- Query the status of the job:
2025-09-16 14:14:24,946	INFO cli.py:296 -- [1mray job status raysubmit_GcFT3P9Kk75xEucD[22m
2025-09-16 14:14:24,946	INFO cli.py:298 -- Request the job to be stopped:
2025-09-16 14:14:24,946	INFO cli.py:300 -- [1mray job stop raysubmit_GcFT3P9Kk75xEucD[22m
2025-09-16 14:14:24,949	INFO cli.py:307 -- Tailing logs until the job exits (disable with --no-wait):
2025-09-16 14:14:24,398	INFO job_manager.py:530 -- Runtime env is setting up.
/leonardo_scratch/large/userinternal/rscheda0/benchmarks/inference/inference-Leonardo/env_vllm/bin/python
serve.sh: LAUNCH_FOLDER: /leonardo_scratch/large/userinternal/rscheda0/benchmarks/inference/inference-Leonardo/results/vllm/sharegpt/Llama-3.1-405B/Nodes_8-GPUs_4-TP_32-PP_1/launch-1
serve.sh: ADDITIONAL_ARGS: --max-model-len=32000 --cpu-offload-gb=0.5
Waiting for vLLM server to be ready...
Waiting for vLLM server to be ready...
INFO 09-16 14:17:53 [__init__.py:244] Automatically detected platform cuda.
INFO 09-16 14:18:35 [api_server.py:1287] vLLM API server version 0.9.1
INFO 09-16 14:18:36 [cli_args.py:309] non-default args: {'port': 2950, 'model': '/leonardo_scratch/large/userinternal/lcavall1/llama405_mlperf/model//Llama-3.1-405B', 'max_model_len': 32000, 'enforce_eager': True, 'distributed_executor_backend': 'ray', 'tensor_parallel_size': 32, 'swap_space': 2.0, 'cpu_offload_gb': 0.5, 'enable_chunked_prefill': True}
INFO 09-16 14:18:56 [config.py:823] This model supports multiple tasks: {'reward', 'score', 'classify', 'embed', 'generate'}. Defaulting to 'generate'.
INFO 09-16 14:18:56 [config.py:2195] Chunked prefill is enabled with max_num_batched_tokens=2048.
WARNING 09-16 14:18:56 [cuda.py:91] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
WARNING 09-16 14:19:00 [env_override.py:17] NCCL_CUMEM_ENABLE is set to 0, skipping override. This may increase memory overhead with cudagraph+allreduce: https://github.com/NVIDIA/nccl/issues/1234
INFO 09-16 14:19:03 [__init__.py:244] Automatically detected platform cuda.
INFO 09-16 14:19:08 [core.py:455] Waiting for init message from front-end.
INFO 09-16 14:19:08 [core.py:70] Initializing a V1 LLM engine (v0.9.1) with config: model='/leonardo_scratch/large/userinternal/lcavall1/llama405_mlperf/model//Llama-3.1-405B', speculative_config=None, tokenizer='/leonardo_scratch/large/userinternal/lcavall1/llama405_mlperf/model//Llama-3.1-405B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=32, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/leonardo_scratch/large/userinternal/lcavall1/llama405_mlperf/model//Llama-3.1-405B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":[],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"max_capture_size":0,"local_cache_dir":null}
2025-09-16 14:19:08,498	INFO worker.py:1514 -- Using address 10.8.0.144:6379 set in the environment variable RAY_ADDRESS
2025-09-16 14:19:08,498	INFO worker.py:1654 -- Connecting to existing Ray cluster at address: 10.8.0.144:6379...
2025-09-16 14:19:08,506	INFO worker.py:1832 -- Connected to Ray cluster. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
INFO 09-16 14:19:08 [ray_utils.py:334] No current placement group found. Creating a new placement group.
WARNING 09-16 14:19:09 [ray_utils.py:198] tensor_parallel_size=32 is bigger than a reserved number of GPUs (4 GPUs) in a node 85192534de0512bbefc7919b7d29d6fa56897b87853056f9a8d30ddf. Tensor parallel workers can be spread out to 2+ nodes which can degrade the performance unless you have fast interconnect across nodes, like Infiniband. To resolve this issue, make sure you have more than 32 GPUs available at each node.
WARNING 09-16 14:19:09 [ray_utils.py:198] tensor_parallel_size=32 is bigger than a reserved number of GPUs (4 GPUs) in a node fb1bb00c9134e2bf4aef5ec74351cc93bb382149991224b16b0bb43d. Tensor parallel workers can be spread out to 2+ nodes which can degrade the performance unless you have fast interconnect across nodes, like Infiniband. To resolve this issue, make sure you have more than 32 GPUs available at each node.
WARNING 09-16 14:19:09 [ray_utils.py:198] tensor_parallel_size=32 is bigger than a reserved number of GPUs (4 GPUs) in a node 8d355561459293a72ede9d2b53139a976ce267e1facae9d4a0d899a4. Tensor parallel workers can be spread out to 2+ nodes which can degrade the performance unless you have fast interconnect across nodes, like Infiniband. To resolve this issue, make sure you have more than 32 GPUs available at each node.
WARNING 09-16 14:19:09 [ray_utils.py:198] tensor_parallel_size=32 is bigger than a reserved number of GPUs (4 GPUs) in a node cc65e316661fe07b197497fe8f59c8e42ea83ae813f291088401dba8. Tensor parallel workers can be spread out to 2+ nodes which can degrade the performance unless you have fast interconnect across nodes, like Infiniband. To resolve this issue, make sure you have more than 32 GPUs available at each node.
WARNING 09-16 14:19:09 [ray_utils.py:198] tensor_parallel_size=32 is bigger than a reserved number of GPUs (4 GPUs) in a node cd87c88466c73e97bf6bc404b31a4027a539889bde561360a0e741b0. Tensor parallel workers can be spread out to 2+ nodes which can degrade the performance unless you have fast interconnect across nodes, like Infiniband. To resolve this issue, make sure you have more than 32 GPUs available at each node.
WARNING 09-16 14:19:09 [ray_utils.py:198] tensor_parallel_size=32 is bigger than a reserved number of GPUs (4 GPUs) in a node 365b5b86090731b521380c962842c312e285fd57da44615c98026c5b. Tensor parallel workers can be spread out to 2+ nodes which can degrade the performance unless you have fast interconnect across nodes, like Infiniband. To resolve this issue, make sure you have more than 32 GPUs available at each node.
WARNING 09-16 14:19:09 [ray_utils.py:198] tensor_parallel_size=32 is bigger than a reserved number of GPUs (4 GPUs) in a node d50120a9bb735fe7109aeeb41470d3dfaa6e87e5dd939c97e06a4006. Tensor parallel workers can be spread out to 2+ nodes which can degrade the performance unless you have fast interconnect across nodes, like Infiniband. To resolve this issue, make sure you have more than 32 GPUs available at each node.
WARNING 09-16 14:19:09 [ray_utils.py:198] tensor_parallel_size=32 is bigger than a reserved number of GPUs (4 GPUs) in a node 15ecba731ca2d3b24198f3f61bf7a882998b00f6637636b0405d8a5e. Tensor parallel workers can be spread out to 2+ nodes which can degrade the performance unless you have fast interconnect across nodes, like Infiniband. To resolve this issue, make sure you have more than 32 GPUs available at each node.
INFO 09-16 14:19:09 [ray_distributed_executor.py:177] use_ray_spmd_worker: True
[36m(pid=3992873)[0m INFO 09-16 14:19:17 [__init__.py:244] Automatically detected platform cuda.
[36m(pid=333724, ip=10.8.0.173)[0m INFO 09-16 14:20:58 [__init__.py:244] Automatically detected platform cuda.[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=411110, ip=10.8.0.235)[0m INFO 09-16 14:24:19 [__init__.py:244] Automatically detected platform cuda.[32m [repeated 24x across cluster][0m
INFO 09-16 14:25:09 [ray_distributed_executor.py:353] non_carry_over_env_vars from config: set()
INFO 09-16 14:25:09 [ray_distributed_executor.py:355] Copying the following environment variables to workers: ['VLLM_USE_RAY_SPMD_WORKER', 'VLLM_USE_RAY_COMPILED_DAG', 'VLLM_WORKER_MULTIPROC_METHOD', 'VLLM_USE_V1']
INFO 09-16 14:25:09 [ray_distributed_executor.py:358] If certain env vars should NOT be copied to workers, add them to /leonardo/home/userinternal/rscheda0/.config/vllm/ray_non_carry_over_env_vars.json file
[36m(RayWorkerWrapper pid=333724, ip=10.8.0.173)[0m WARNING 09-16 14:25:45 [utils.py:2737] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x14637f3e85d0>
[36m(pid=411107, ip=10.8.0.235)[0m INFO 09-16 14:24:19 [__init__.py:244] Automatically detected platform cuda.[32m [repeated 3x across cluster][0m
[36m(RayWorkerWrapper pid=411110, ip=10.8.0.235)[0m INFO 09-16 14:25:57 [utils.py:1126] Found nccl from library libnccl.so.2
[36m(RayWorkerWrapper pid=411110, ip=10.8.0.235)[0m INFO 09-16 14:25:57 [pynccl.py:70] vLLM is using nccl==2.26.2
[36m(RayWorkerWrapper pid=558828, ip=10.8.0.214)[0m WARNING 09-16 14:25:49 [utils.py:2737] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x14db5380ef50>[32m [repeated 31x across cluster][0m
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO cudaDriverVersion 12020
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ib0,ib1,ib2,ib3
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Bootstrap: Using ib0:10.128.48.53<0>
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ib0,ib1,ib2,ib3
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO NCCL_IB_HCA set to mlx5_0,mlx5_1,mlx5_4,mlx5_5
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0:10.128.48.53<0>
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Using network IB
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO ncclCommInitRank comm 0xd529ae0 rank 14 nranks 32 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x382d1da1bb58e991 - Init START
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO RAS client listening socket at ::1<28028>
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Bootstrap timings total 5.200420 (create 0.000016, send 0.000205, recv 0.000110, ring 5.199879, delay 0.000001)
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO NCCL_CUMEM_ENABLE set by environment to 0.
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Setting affinity for GPU 2 to ffff
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO NCCL_NVLS_ENABLE set by environment to 0.
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO comm 0xd529ae0 rank 14 nRanks 32 nNodes 8 localRanks 4 localRank 2 MNNVL 0
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Trees [0] 15/-1/-1->14->10 [1] 15/-1/-1->14->10 [2] 15/6/-1->14->30 [3] 15/6/-1->14->30
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO P2P Chunksize set to 131072
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:334597 [2] NCCL INFO [Proxy Service] Device 2 CPU core 5
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:334601 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 11
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Channel 00/0 : 11[3] -> 14[2] [receive] via NET/IB/2
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Channel 02/0 : 11[3] -> 14[2] [receive] via NET/IB/2
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:334604 [2] NCCL INFO [Proxy Progress] Device 2 CPU core 14
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Channel 01/0 : 14[2] -> 19[3] [send] via NET/IB/3
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Channel 03/0 : 14[2] -> 19[3] [send] via NET/IB/3
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Channel 00/0 : 14[2] -> 13[1] via P2P/IPC/read
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Channel 02/0 : 14[2] -> 13[1] via P2P/IPC/read
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 0
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Channel 00/0 : 14[2] -> 15[3] via P2P/IPC/read
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Channel 01/0 : 14[2] -> 15[3] via P2P/IPC/read
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Channel 02/0 : 14[2] -> 15[3] via P2P/IPC/read
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Channel 03/0 : 14[2] -> 15[3] via P2P/IPC/read
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Channel 00/0 : 10[2] -> 14[2] [receive] via NET/IB/2
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Channel 01/0 : 10[2] -> 14[2] [receive] via NET/IB/3
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Channel 02/0 : 6[2] -> 14[2] [receive] via NET/IB/2
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Channel 03/0 : 6[2] -> 14[2] [receive] via NET/IB/3
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Channel 02/0 : 30[2] -> 14[2] [receive] via NET/IB/2
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Channel 03/0 : 30[2] -> 14[2] [receive] via NET/IB/3
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Channel 02/0 : 14[2] -> 30[2] [send] via NET/IB/2
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Channel 03/0 : 14[2] -> 30[2] [send] via NET/IB/3
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Channel 02/0 : 14[2] -> 6[2] [send] via NET/IB/2
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Channel 03/0 : 14[2] -> 6[2] [send] via NET/IB/3
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Channel 00/0 : 14[2] -> 10[2] [send] via NET/IB/2
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Channel 01/0 : 14[2] -> 10[2] [send] via NET/IB/3
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m lrdn2693:333723:333723 [2] NCCL INFO Co
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m INFO 09-16 14:25:57 [utils.py:1126] Found nccl from library libnccl.so.2[32m [repeated 31x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m INFO 09-16 14:25:57 [pynccl.py:70] vLLM is using nccl==2.26.2[32m [repeated 31x across cluster][0m
[36m(RayWorkerWrapper pid=1903145, ip=10.8.0.154)[0m lrdn2674:1903145:1903145 [2] NCCL INFO Connected all trees
[36m(RayWorkerWrapper pid=1903145, ip=10.8.0.154)[0m lrdn2674:19031
[36m(RayWorkerWrapper pid=411110, ip=10.8.0.235)[0m lrdn2755:411110:411110 [2] NCCL INFO threadThresholds 8/8/64 | 256/
[36m(RayWorkerWrapper pid=442184, ip=10.8.0.239)[0m lrdn2759:442184:442184 [2] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 512 | 512
[36m(RayWorkerWrapper pid=442184, ip=10.8.0.239)[0m lrdn2759:442184:442184 [2] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 1 p2p channels per peer
[36m(RayWorkerWrapper pid=442184, ip=10.8.0.239)[0m lrdn2759:442184:442184 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
[36m(RayWorkerWrapper pid=442184, ip=10.8.0.239)[0m lrd
[36m(RayWorkerWrapper pid=401057, ip=10.8.0.187)[0m lrdn2707:401057:40
[36m(RayWorkerWrapper pid=401055, ip=10.8.0.187)[0m lrdn2707:401055:401055 [2] NCCL INFO 
[36m(RayWorkerWrapper pid=3992873)[0m lrdn2664:3992873:3992873 [0] NCCL INFO Channel 00/04 :  0  3  6  5  4  7 10  9  8 11 14 13 12 15 18 17 16 19 22 21 20 23 26 25 24 27 30 29 28 31  2  1
[36m(RayWorkerWrapper pid=3992873)[0m lrdn2664:3992873:3992873 [0] NCCL INFO Channel 01/04 :  0  2  7  5  4  6 11  9  8 10 15 13 12 14 19 17 16 18 23 21 20 22 27 25 24 26 31 29 28 30  3  1
[36m(RayWorkerWrapper pid=3992873)[0m lrdn2664:3992873:3992873 [0] NCCL INFO Channel 02/04 :  0  3  6  5  4  7 10  9  8 11 14 13 12 15 18 17 16 19 22 21 20 23 26 25 24 27 30 29 28 31  2  1
[36m(RayWorkerWrapper pid=3992873)[0m lrdn2664:3992873:3992873 [0] NCCL INFO Channel 03/04 :  0  2  7  5  4  6 11  9  8 10 15 13 12 14 19 17 16 18 23 21 20 22 27 25 24 26 31 29 28 30  3  1
[36m(RayWorkerWrapper pid=3992873)[0m lrdn2664:3992873:3992873 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
[36m(RayWorkerWrapper pid=3992873)[0m lrdn2664:3992873:3992873 [0] NCCL INFO CC Off, workFifoBytes 1048576
[36m(RayWorkerWrapper pid=3992875)[0m lrdn2664:3992875:3992875 [2] NCCL INFO TUNER/Plugin: Could not fin
[36m(RayWorkerWrapper pid=3992876)[0m lrdn2664:3992876:3992876 [3] NCCL INFO ncclCommInitRank comm 0xd0b5f10 rank 3 nranks 32 cudaDev 3 nvmlDev 3 busId c8000 commId 0x382d1da1bb58e991 - Init COMPLETE
[36m(RayWorkerWrapper pid=3992876)[0m lrdn2664:3992876:3992876 [3] NCCL INFO Init timings - ncclCommInitRank: rank 3 nranks 32 total 2.53 (kernels 0.23, alloc 0.03, bootstrap 2.05, allgathers 0.01, topo 
[36m(RayWorkerWrapper pid=558830, ip=10.8.0.214)[0m lrdn2734:558830:558830 [2] NCCL INFO threadThresholds 8/8/64
[36m(RayWorkerWrapper pid=558828, ip=10.8.0.214)[0m lrdn2734:558828:558828 [3] NCCL INFO ncclCommInitRank comm 0xe44e3d0 rank 23 nranks 32 cudaDev 3 nvmlDev 
[36m(RayWorkerWrapper pid=3541007, ip=10.8.0.169)[0m lrdn2689:3541007:3541007 [3] NCCL I
[36m(RayWorkerWrapper pid=3541006, ip=10.8.0.169)[0m lrdn2689:3541006:3541006 [2] NCCL INFO Conne
[36m(RayWorkerWrapper pid=333724, ip=10.8.0.173)[0m lrdn2693:333724:3337
[36m(RayWorkerWrapper pid=1903143, ip=10.8.0.154)[0m lrdn2674:1903143:1903143 [3] NCCL INFO ncclCommInitRank com
[36m(RayWorkerWrapper pid=411109, ip=10.8.0.235)[0m lrdn2755:411109:411109 [3] NCCL INFO ncclCommInitRank comm 0xdf78ab0 rank 27 nranks 32 cudaDev 3 nvmlDev 3 bu
[36m(RayWorkerWrapper pid=3992873)[0m  TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
[36m(RayWorkerWrapper pid=3992873)[0m lrdn2664:3992873:3992873 [0] NCCL INFO Init timings - ncclCommInitRank: rank 0 nranks 32 total 2.54 (kernels 0.23, alloc 0.08, bootstrap 2.00, allgathers 0.01, topo 0.06, graphs 0.01, connections 0.14, rest 0.01)
[36m(RayWorkerWrapper pid=3992875)[0m d: libnccl-tuner.so. Using internal tuner plugin.
[36m(RayWorkerWrapper pid=3992876)[0m 0.06, graphs 0.01, connections 0.14, rest 0.00)
[36m(RayWorkerWrapper pid=333723, ip=10.8.0.173)[0m nnected all trees
[36m(RayWorkerWrapper pid=1903143, ip=10.8.0.154)[0m m 0xcbf72a0 rank 7 nranks 32 cudaDev 3 nvmlDev 3 busId c8000 commId 0x382d1da1bb58e991 - Init COMPLETE
[36m(RayWorkerWrapper pid=411110, ip=10.8.0.235)[0m 8/64 | 512 | 512
[36m(RayWorkerWrapper pid=411109, ip=10.8.0.235)[0m sId c8000 commId 0x382d1da1bb58e991 - Init COMPLETE
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO cudaDriverVersion 12020[32m [repeated 25x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ib0,ib1,ib2,ib3[32m [repeated 50x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO Bootstrap: Using ib0:10.128.49.45<0>[32m [repeated 25x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO NCCL version 2.26.2+cuda12.2[32m [repeated 25x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.[32m [repeated 25x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.[32m [repeated 25x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO NCCL_IB_HCA set to mlx5_0,mlx5_1,mlx5_4,mlx5_5[32m [repeated 25x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0:10.128.49.45<0>[32m [repeated 25x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. [32m [repeated 25x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO Using network IB[32m [repeated 25x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO ncclCommInitRank comm 0xdccaaa0 rank 24 nranks 32 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x382d1da1bb58e991 - Init START[32m [repeated 25x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO RAS client listening socket at ::1<28028>[32m [repeated 25x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO Bootstrap timings total 0.003515 (create 0.000017, send 0.000160, recv 0.000212, ring 0.002577, delay 0.000000)[32m [repeated 25x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO NCCL_CUMEM_ENABLE set by environment to 0.[32m [repeated 25x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO Setting affinity for GPU 0 to ffff[32m [repeated 25x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO NCCL_NVLS_ENABLE set by environment to 0.[32m [repeated 25x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO comm 0xdccaaa0 rank 24 nRanks 32 nNodes 8 localRanks 4 localRank 0 MNNVL 0[32m [repeated 25x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO Trees [0] 25/-1/-1->24->27 [1] 25/-1/-1->24->27 [2] 25/-1/-1->24->27 [3] 25/-1/-1->24->27[32m [repeated 25x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO P2P Chunksize set to 131072[32m [repeated 25x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:412127 [0] NCCL INFO [Proxy Service] Device 0 CPU core 9[32m [repeated 25x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:412131 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 12[32m [repeated 25x across cluster][0m
[36m(RayWorkerWrapper pid=442186, ip=10.8.0.239)[0m lrdn2759:442186:442186 [3] NCCL INFO Channel 03/0 : 26[2] -> 31[3] [receive] via NET/IB/3[32m [repeated 76x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:412135 [0] NCCL INFO [Proxy Progress] Device 0 CPU core 2[32m [repeated 25x across cluster][0m
[36m(RayWorkerWrapper pid=442186, ip=10.8.0.239)[0m lrdn2759:442186:442186 [3] NCCL INFO Channel 02/0 : 31[3] -> 2[2] [send] via NET/IB/2[32m [repeated 76x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO Channel 03/0 : 24[0] -> 27[3] via P2P/IPC/read[32m [repeated 192x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 0[32m [repeated 25x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO Connected all trees[32m [repeated 22x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 512 | 512[32m [repeated 21x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 1 p2p channels per peer[32m [repeated 22x across cluster][0m
[36m(RayWorkerWrapper pid=411107, ip=10.8.0.235)[0m lrdn2755:411107:411107 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.[32m [repeated 20x across cluster][0m
[36m(RayWorkerWrapper pid=3992873)[0m lrdn2664:3992873:3992873 [0] NCCL INFO
[36m(RayWorkerWrapper pid=401057, ip=10.8.0.187)[0m 1057 [3] NCCL INFO ncclCommInitRank comm 0xc859f60 rank 19 nranks 32 cudaDev 3 nvmlDev 3 busId c8000 commId 0x382d1da1bb58e991 - Init COMPLETE[32m [repeated 18x across cluster][0m
[36m(RayWorkerWrapper pid=401057, ip=10.8.0.187)[0m lrdn2707:401057:401057 [3] NCCL INFO Init timings - ncclCommInitRank: rank 19 nranks 32 total 2.07 (kernels 0.28, alloc 0.04, bootstrap 1.51, allgathers 0.01, topo 0.06, graphs 0.01, connections 0.14, rest 0.02)[32m [repeated 19x across cluster][0m
[36m(RayWorkerWrapper pid=401055, ip=10.8.0.187)[0m Connected all trees
[36m(RayWorkerWrapper pid=558830, ip=10.8.0.214)[0m  | 256/8/64 | 512 | 512
[36m(RayWorkerWrapper pid=558828, ip=10.8.0.214)[0m 3 busId c8000 commId 0x382d1da1bb58e991 - Init COMPLETE
[36m(RayWorkerWrapper pid=3541007, ip=10.8.0.169)[0m NFO ncclCommInitRank comm 0xcc9e780 rank 11 nranks 32 cudaDev 3 nvmlDev 3 busId c8000 commId 0x382d1da1bb58e991 - Init COMPLETE
[36m(RayWorkerWrapper pid=3541006, ip=10.8.0.169)[0m cted all trees
[36m(RayWorkerWrapper pid=3992873)[0m WARNING 09-16 14:26:31 [custom_all_reduce.py:85] Custom allreduce is disabled because this process group spans across nodes.
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO cudaDriverVersion 12020[32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ib0,ib1,ib2,ib3[32m [repeated 12x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO Bootstrap: Using ib0:10.128.48.37<0>[32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO NCCL version 2.26.2+cuda12.2[32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.[32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.[32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO NCCL_IB_HCA set to mlx5_0,mlx5_1,mlx5_4,mlx5_5[32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0:10.128.48.37<0>[32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. [32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO Using network IB[32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO ncclCommInitRank comm 0xe5d9b00 rank 9 nranks 32 cudaDev 1 nvmlDev 1 busId 56000 commId 0x382d1da1bb58e991 - Init START[32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO RAS client listening socket at ::1<28028>[32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO Bootstrap timings total 0.398476 (create 0.000016, send 0.000054, recv 0.000097, ring 0.398101, delay 0.000000)[32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO NCCL_CUMEM_ENABLE set by environment to 0.[32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO Setting affinity for GPU 1 to ffff[32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO NCCL_NVLS_ENABLE set by environment to 0.[32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO comm 0xe5d9b00 rank 9 nRanks 32 nNodes 8 localRanks 4 localRank 1 MNNVL 0[32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO Trees [0] -1/-1/-1->9->8 [1] -1/-1/-1->9->8 [2] -1/-1/-1->9->8 [3] -1/-1/-1->9->8[32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO P2P Chunksize set to 131072[32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541892 [1] NCCL INFO [Proxy Service] Device 1 CPU core 11[32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541896 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 13[32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541901 [1] NCCL INFO [Proxy Progress] Device 1 CPU core 4[32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO Channel 03/0 : 9[1] -> 8[0] via P2P/IPC/read[32m [repeated 42x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 0[32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO Connected all trees[32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 512 | 512[32m [repeated 8x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 1 p2p channels per peer[32m [repeated 9x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.[32m [repeated 9x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO ncclCommInitRank comm 0xe5d9b00 rank 9 nranks 32 cudaDev 1 nvmlDev 1 busId 56000 commId 0x382d1da1bb58e991 - Init COMPLETE[32m [repeated 9x across cluster][0m
[36m(RayWorkerWrapper pid=3541008, ip=10.8.0.169)[0m lrdn2689:3541008:3541008 [1] NCCL INFO Init timings - ncclCommInitRank: rank 9 nranks 32 total 0.88 (kernels 0.19, alloc 0.06, bootstrap 0.40, allgathers 0.01, topo 0.06, graphs 0.01, connections 0.08, rest 0.08)[32m [repeated 11x across cluster][0m
[36m(RayWorkerWrapper pid=3992873)[0m INFO 09-16 14:26:31 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_dcba3e40'), local_subscribe_addr='ipc:///tmp/ba6394f5-e01c-4a59-a450-48f2c1a2a374', remote_subscribe_addr='tcp://10.8.0.144:38769', remote_addr_ipv6=False)
[36m(RayWorkerWrapper pid=442185, ip=10.8.0.239)[0m INFO 09-16 14:26:31 [parallel_state.py:1065] rank 29 in world size 32 is assigned as DP rank 0, PP rank 0, TP rank 29, EP rank 29
[36m(RayWorkerWrapper pid=3541007, ip=10.8.0.169)[0m WARNING 09-16 14:26:32 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[36m(RayWorkerWrapper pid=3541007, ip=10.8.0.169)[0m INFO 09-16 14:26:32 [gpu_model_runner.py:1595] Starting to load model /leonardo_scratch/large/userinternal/lcavall1/llama405_mlperf/model//Llama-3.1-405B...
[36m(RayWorkerWrapper pid=401056, ip=10.8.0.187)[0m INFO 09-16 14:26:32 [gpu_model_runner.py:1600] Loading model from scratch...
[36m(RayWorkerWrapper pid=3992873)[0m INFO 09-16 14:26:34 [cuda.py:252] Using Flash Attention backend on V1 engine.
[36m(RayWorkerWrapper pid=3992873)[0m 
Loading safetensors checkpoint shards:   0% Completed | 0/191 [00:00<?, ?it/s]
Ray Cluster started with PID 3988803
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
Don't kill process 3988803, it is still running
